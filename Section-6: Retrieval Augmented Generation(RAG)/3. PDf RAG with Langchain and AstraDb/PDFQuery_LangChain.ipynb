{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgOhk8U4Rpl"
      },
      "source": [
        "# Quickstart: Querying PDF With Astra and LangChain\n",
        "\n",
        "### A question-answering demo using Astra DB and LangChain, powered by Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqfJKgRM4Rpo"
      },
      "source": [
        "#### Pre-requisites:\n",
        "\n",
        "You need a **_Serverless Cassandra with Vector Search_** database on [Astra DB](https://astra.datastax.com) to run this demo. As outlined in more detail [here](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html#_prepare_for_using_your_vector_database), you should get a DB Token with role _Database Administrator_ and copy your Database ID: these connection parameters are needed momentarily.\n",
        "\n",
        "You also need an [OpenAI API Key](https://cassio.org/start_here/#llm-access) for this demo to work.\n",
        "\n",
        "#### What you will do:\n",
        "\n",
        "- Setup: import dependencies, provide secrets, create the LangChain vector store;\n",
        "- Run a Question-Answering loop retrieving the relevant headlines and having an LLM construct the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQN-L2J4Rpq"
      },
      "source": [
        "Import the packages you'll need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V4qBIihE4Rpq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vpsr/Desktop/python/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# LangChain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import Ollama\n",
        "from langchain.embeddings import OllamaEmbeddings\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1itBNL1v6N9-"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2UauiC4Rpr"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eqpM6I854Rpr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "ASTRA_DB_ID = os.getenv(\"ASTRA_DB_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1cmD5EF4Rpr"
      },
      "source": [
        "#### Provide your secrets:\n",
        "\n",
        "Replace the following with your Astra DB connection details and your OpenAI API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "waVKJW-n6jqJ"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('budget_speech.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "42BKuFRO6meP"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "vR41Iq-4ZHnG",
        "outputId": "861bc27a-fd4d-47f9-f722-8e365a6fd030"
      },
      "outputs": [],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S0GgIQs4Rps"
      },
      "source": [
        "Initialize the connection to your database:\n",
        "\n",
        "_(do not worry if you see a few warnings, it's just that the drivers are chatty about negotiating protocol versions with the DB.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFBR5HnZSPmK",
        "outputId": "5b4bb3ea-6be3-4d7a-c535-88715fa67c13"
      },
      "outputs": [],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7NxZYb4Rps"
      },
      "source": [
        "Create the LangChain embedding and LLM objects for later usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TavS0AK2SLrL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8714/1405882813.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
            "  embedding = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")\n"
          ]
        }
      ],
      "source": [
        "llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
        "embedding = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HMMx5Pm4Rpt"
      },
      "source": [
        "Create your LangChain vector store ... backed by Astra DB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bg9VAk4USQvU"
      },
      "outputs": [],
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9FMAhKr77AVO"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BDHAyT7Gjr",
        "outputId": "7833f6ac-bd97-40d6-fcbe-94a81b4dd6ac"
      },
      "outputs": [],
      "source": [
        "texts[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1WK54-74Rpt"
      },
      "source": [
        "### Load the dataset into the vector store\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX5BECsdSUUM",
        "outputId": "cdff3467-8af3-45cd-f750-f3174bc521fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 50 headlines.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "astra_vector_store.add_texts(texts[:50])\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts[:50]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhVf0kir2Uke"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLJp8yPF4Rpt"
      },
      "source": [
        "### Run the QA cycle\n",
        "\n",
        "Simply run the cells and ask a question -- or `quit` to stop. (you can also stop execution with the \"▪\" button on the top toolbar)\n",
        "\n",
        "Here are some suggested questions:\n",
        "- _What is the current GDP?_\n",
        "- _How much the agriculture target will be increased to and what the focus will be_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJugrh7SX3C",
        "outputId": "10e8f954-a113-47a2-a84c-615a9f6e5dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "QUESTION: \"How much the agriculture target will be increased to and what the focus will be\"\n",
            "ANSWER: \"<think>\n",
            "Okay, let me try to figure out how much the agriculture target is increased and what the focus will be based on the context provided.\n",
            "\n",
            "First, I see that in section 9, they mention a Prime Minister Dhan-Dhaanya Krishi Yojana - Developing Agri Districts Programme. This seems to be a initiative aimed at enhancing agricultural productivity. The description talks about improving agricultural practices like augmentation of post-harvest storage, better irrigation facilities, and facilitating rural areas for migration. It also mentions that this programme will focus on various groups such as rural women, young farmers, rural youth, marginal and small farmers, and landless families.\n",
            "\n",
            "In section 10, it says that the government plans to enhance agricultural productivity through several specific actions: enhancing productivity by improving crop diversification and sustainable practices, augmenting post-harvest storage at panchayats and blocks, improving irrigation, facilitating rural areas for migration, and covering 100 districts with low productivity, moderate crop intensity, and below-average credit parameters. It also emphasizes that the focus will be on rural women, young farmers, rural youth, etc.\n",
            "\n",
            "In section 12, it details the same activities but specifically notes that it's aimed at rural women, young farmers, rural youth, marginal and small farmers, and landless families. They also mention specific pulses like atmanirbhrata in Pulses and vegetables & fruits.\n",
            "\n",
            "Putting this together, the target is increased through various measures to enhance agricultural productivity. The focus of these initiatives is specifically on rural groups such as women, young farmers, rural youth, marginal farmers, small farmers, and landless families. The aim is to improve their farming practices and ensure better access for them in rural areas.\n",
            "</think>\n",
            "\n",
            "The agriculture target is increased through various measures aimed at enhancing agricultural productivity. The focus of these initiatives is specifically on rural groups such as women, young farmers, rural youth, marginal farmers, small farmers, and landless families. The goal is to improve their farming practices and ensure better access for them in rural areas.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n",
            "    [0.8680] \"sustainable agriculture practices, (3) augment post -harvest stor age at the \n",
            "pancha ...\"\n",
            "    [0.8672] \"9. Now I move to specific proposals, beginning with ‘Agriculture as the 1st \n",
            "Engine’ ...\"\n",
            "    [0.8597] \"rural areas so that migration is an option, but not a necessity.  \n",
            "12. The programme ...\"\n",
            "    [0.8551] \"in Pulses” with a special focus on Tur, Urad and Masoor.  Details are in \n",
            "Annexure B ...\"\n"
          ]
        }
      ],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSaUPguw389l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
