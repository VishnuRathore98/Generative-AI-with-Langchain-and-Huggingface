{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Seq2Seq (Sequence-to-Sequence) model using LSTM networks for English-to-French translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 09:31:47.643083: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-02 09:31:52.937573: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-02 09:31:56.103418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738468918.425242    4920 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738468918.740551    4920 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-02 09:32:02.338805: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample English-French Sentences\n",
    "english_sentences = ['hello', 'how are you', 'good morning']\n",
    "french_sentences = ['bonjour', 'comment ça va', 'bonjour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Padding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Tokenize and Pad Sequences\n",
    "def tokenize_and_pad(sentences, num_words=1000, max_len=10):\n",
    "    tokenizer = Tokenizer(num_words=num_words, filters='')\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "    return tokenizer, padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Tokenization\n",
    "\n",
    "eng_tokenizer, eng_input_data = tokenize_and_pad(english_sentences)\n",
    "french_tokenizer, french_target_data = tokenize_and_pad(french_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "french_vocab_size = len(french_tokenizer.word_index) + 1\n",
    "max_len = 10  # Maximum sequence length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Encoder\n",
    "def build_encoder(vocab_size, embedding_dim=256, lstm_units=256):\n",
    "    encoder_inputs = Input(shape=(max_len,))\n",
    "    enc_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "    _, state_h, state_c = encoder_lstm(enc_emb)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    return encoder_inputs, encoder_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 09:33:30.468375: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Create Encoder\n",
    "encoder_inputs, encoder_states = build_encoder(eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Decoder\n",
    "def build_decoder(vocab_size, embedding_dim=256, lstm_units=256):\n",
    "    decoder_inputs = Input(shape=(max_len,))\n",
    "    dec_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    return decoder_inputs, decoder_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decoder\n",
    "decoder_inputs, decoder_outputs = build_decoder(french_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Seq2Seq Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Training Data\n",
    "y_train = np.expand_dims(french_target_data, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpsr/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_6']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.0333 - loss: 1.6100\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.1667 - loss: 1.5732\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1667 - loss: 1.5358\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.1667 - loss: 1.4964\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1667 - loss: 1.4535\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1667 - loss: 1.4060\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1667 - loss: 1.3525\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1667 - loss: 1.2920\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1667 - loss: 1.2234\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.1667 - loss: 1.1464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f0d8c3a3b20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model\n",
    "model.fit([eng_input_data, french_target_data], y_train, batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencing for translation\n",
    "def translate_sentence(sentence):\n",
    "    sequence = eng_tokenizer.texts_to_sequences([sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "    states_value = model.layers[2].predict(padded_sequence)\n",
    "\n",
    "    target_seq = np.zeros((1, max_len))\n",
    "    target_seq[0, 0] = french_tokenizer.word_index['start'] if 'start' in french_tokenizer.word_index else 1\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    for _ in range(max_len):\n",
    "        output_tokens, h, c = model.layers[3].predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = french_tokenizer.index_word.get(sampled_token_index, '')\n",
    "        if sampled_word == 'end':\n",
    "            break\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/vpsr/Desktop/python/Generative AI with Langchain and Huggingface/Section-3: Deep Learning for NLP/6. Encoder and Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vpsr/Desktop/python/Generative%20AI%20with%20Langchain%20and%20Huggingface/Section-3%3A%20Deep%20Learning%20for%20NLP/6.%20Encoder%20and%20Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(translate_sentence(\u001b[39m'\u001b[39;49m\u001b[39mhello\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;32m/home/vpsr/Desktop/python/Generative AI with Langchain and Huggingface/Section-3: Deep Learning for NLP/6. Encoder and Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vpsr/Desktop/python/Generative%20AI%20with%20Langchain%20and%20Huggingface/Section-3%3A%20Deep%20Learning%20for%20NLP/6.%20Encoder%20and%20Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sequence \u001b[39m=\u001b[39m eng_tokenizer\u001b[39m.\u001b[39mtexts_to_sequences([sentence])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vpsr/Desktop/python/Generative%20AI%20with%20Langchain%20and%20Huggingface/Section-3%3A%20Deep%20Learning%20for%20NLP/6.%20Encoder%20and%20Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m padded_sequence \u001b[39m=\u001b[39m pad_sequences(sequence, maxlen\u001b[39m=\u001b[39mmax_len, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vpsr/Desktop/python/Generative%20AI%20with%20Langchain%20and%20Huggingface/Section-3%3A%20Deep%20Learning%20for%20NLP/6.%20Encoder%20and%20Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m states_value \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(padded_sequence)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vpsr/Desktop/python/Generative%20AI%20with%20Langchain%20and%20Huggingface/Section-3%3A%20Deep%20Learning%20for%20NLP/6.%20Encoder%20and%20Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m target_seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, max_len))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vpsr/Desktop/python/Generative%20AI%20with%20Langchain%20and%20Huggingface/Section-3%3A%20Deep%20Learning%20for%20NLP/6.%20Encoder%20and%20Decoder/A_Seq2Seq_model_using_LSTM_networks.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m target_seq[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m french_tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m french_tokenizer\u001b[39m.\u001b[39mword_index \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "print(translate_sentence('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpsr/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_13', 'keras_tensor_19']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.1000 - loss: 1.6016\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.1667 - loss: 1.5656\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.1667 - loss: 1.5289\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.1667 - loss: 1.4901\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.1667 - loss: 1.4480\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.1667 - loss: 1.4016\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.1667 - loss: 1.3497\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.1667 - loss: 1.2914\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.1667 - loss: 1.2257\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.1667 - loss: 1.1522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpsr/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_19', 'keras_tensor_17CLONE', 'keras_tensor_18CLONE']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "bonjour bonjour bonjour bonjour bonjour bonjour bonjour bonjour bonjour bonjour\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "except ModuleNotFoundError:\n",
    "    print(\"TensorFlow is not installed. Running in a non-TensorFlow environment.\")\n",
    "    tf = None\n",
    "\n",
    "# Sample Data (English-French pairs)\n",
    "english_sentences = ['hello', 'how are you', 'good morning']\n",
    "french_sentences = ['bonjour', 'comment ça va', 'bonjour']\n",
    "\n",
    "def tokenize_and_pad(sentences, num_words=1000, max_len=10):\n",
    "    tokenizer = Tokenizer(num_words=num_words, filters='')\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "    return tokenizer, padded\n",
    "\n",
    "# Tokenize English and French\n",
    "eng_tokenizer, eng_input_data = tokenize_and_pad(english_sentences)\n",
    "french_tokenizer, french_target_data = tokenize_and_pad(french_sentences)\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "french_vocab_size = len(french_tokenizer.word_index) + 1\n",
    "max_len = 10  # Maximum sequence length\n",
    "\n",
    "if tf:\n",
    "    def build_encoder(vocab_size, embedding_dim=256, lstm_units=256):\n",
    "        encoder_inputs = Input(shape=(max_len,))\n",
    "        enc_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "        encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "        encoder_states = [state_h, state_c]\n",
    "        encoder_model = Model(encoder_inputs, encoder_states)\n",
    "        return encoder_inputs, encoder_states, encoder_model\n",
    "\n",
    "    encoder_inputs, encoder_states, encoder_model = build_encoder(eng_vocab_size)\n",
    "\n",
    "    def build_decoder(vocab_size, embedding_dim=256, lstm_units=256):\n",
    "        decoder_inputs = Input(shape=(max_len,))\n",
    "        dec_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "        decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "        decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = Model([decoder_inputs] + encoder_states, [decoder_outputs, state_h, state_c])\n",
    "        return decoder_inputs, decoder_outputs, decoder_model\n",
    "\n",
    "    decoder_inputs, decoder_outputs, decoder_model = build_decoder(french_vocab_size)\n",
    "\n",
    "    try:\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        y_train = np.expand_dims(french_target_data, axis=-1)\n",
    "        model.fit([eng_input_data, french_target_data], y_train, batch_size=32, epochs=10)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during model compilation or training: {e}\")\n",
    "\n",
    "    def translate_sentence(sentence):\n",
    "        sequence = eng_tokenizer.texts_to_sequences([sentence])\n",
    "        padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "        states_value = encoder_model.predict(padded_sequence)\n",
    "\n",
    "        target_seq = np.zeros((1, max_len))\n",
    "        target_seq[0, 0] = french_tokenizer.word_index['start'] if 'start' in french_tokenizer.word_index else 1\n",
    "\n",
    "        decoded_sentence = ''\n",
    "        for _ in range(max_len):\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = french_tokenizer.index_word.get(sampled_token_index, '')\n",
    "            if sampled_word == 'end':\n",
    "                break\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            states_value = [h, c]\n",
    "\n",
    "        return decoded_sentence.strip()\n",
    "\n",
    "    # Example usage\n",
    "    print(translate_sentence('hello'))\n",
    "else:\n",
    "    print(\"Skipping model creation and training due to missing TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
