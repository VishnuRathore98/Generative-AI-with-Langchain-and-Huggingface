{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Bidirectional Recurrent Neural Network (BiRNN)</b>\n",
    "A Bidirectional Recurrent Neural Network (BiRNN) is an extension of the traditional RNN that improves its ability to capture long-range dependencies in sequential data. It achieves this by processing the input sequence in both forward and backward directions, effectively providing two sets of hidden states for each time step.\n",
    "\n",
    "#### How It Works\n",
    "##### A BiRNN consists of two RNNs:\n",
    "\n",
    "* <b>Forward RNN</b> : Processes the sequence from the first to the last time step.\n",
    "* <b>Backward RNN</b> : Processes the sequence from the last to the first time step.\n",
    "\n",
    "At each time step 𝑡 , the output is a combination of the hidden states from both the forward and backward RNNs:\n",
    "\n",
    "        ℎ𝑡=concatenate(ℎ𝑡 forward,ℎ𝑡 backward)\n",
    "\n",
    "This structure allows the model to consider both past and future context when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Bidirectional Simple RNN for Text Classification using the IMDB movie reviews dataset.\n",
    "\n",
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import imdb \n",
    "# dataset contains 50,000 movie reviews labeled as positive or negative.\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "# ensures that all sequences have the same length.\n",
    "\n",
    "from tensorflow.keras.models import Sequential # \n",
    "\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Bidirectional, Dense\n",
    "# Embedding:  converts words into dense vectors.\n",
    "# SimpleRNN:  is the core RNN layer.\n",
    "# Bidirectional: makes the RNN process in both directions.\n",
    "# Dense: is the output layer.\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "# Set random seed for reproduciblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25000, 100), Labels shape: (25000,)\n",
      "Testing data shape: (25000, 100), Labels shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Load IMDB dataset (only keep the top 10,000 most frequent words)\n",
    "vocab_size = 10000\n",
    "max_length = 100  # Maximum review length\n",
    "\n",
    "# We only keep the top 10,000 most common words to reduce model complexity.\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Pad sequences to ensure all reviews are of equal length\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, Labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpsr/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Defining the Bidirectional RNN model\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length),\n",
    "    Bidirectional(SimpleRNN(64, return_sequences=False)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Embedding layer: Converts word indices into 32-dimensional vectors.\n",
    "\n",
    "# Bidirectional SimpleRNN layer: \n",
    "#   Reads text forward and backward to capture both past and future context.\n",
    "#   Uses 64 hidden units (each direction has 64, so total 128 parameters).\n",
    "#   return_sequences=False: keeps only the last output for classification.\n",
    "\n",
    "# Dense layer: Outputs a probability (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# adam: optimizes learning.\n",
    "# binary_crossentropy: is the loss function for binary classification.\n",
    "# accuracy: tracks model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - accuracy: 0.5462 - loss: 0.6815 - val_accuracy: 0.7356 - val_loss: 0.5395\n",
      "Epoch 2/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6168 - loss: 0.6679 - val_accuracy: 0.7754 - val_loss: 0.4726\n",
      "Epoch 3/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.8096 - loss: 0.4292 - val_accuracy: 0.7608 - val_loss: 0.5033\n",
      "Epoch 4/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.8629 - loss: 0.3330 - val_accuracy: 0.7704 - val_loss: 0.5333\n",
      "Epoch 5/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.9005 - loss: 0.2535 - val_accuracy: 0.7551 - val_loss: 0.6279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fef52b87160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "# 5 epochs: Trains the model 5 times over the dataset.\n",
    "# Batch size of 64: Processes 64 reviews at a time.\n",
    "# Validation on test data: Measures generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7554 - loss: 0.6263\n",
      "Test Accuracy: 0.7551\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# Evaluates performance on unseen test data.\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"imdb_reviews_sentiment_analysis_using_bidirectional_simple_rnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a New Review for Prediction\n",
    "\n",
    "# Since our model expects numeric input, we must tokenize and pad new reviews before passing them \n",
    "# into the model.\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define a sample review\n",
    "new_reviews = [\"This movie was absolutely fantastic! I loved it.\",\n",
    "               \"Worst movie ever. I regret watching it.\"]\n",
    "\n",
    "# Tokenizer with the same vocabulary size\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(new_reviews)  # Tokenize new text\n",
    "\n",
    "# Convert text to sequences\n",
    "new_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
    "\n",
    "# Pad sequences to match model input size (max_length=100)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=100, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Review: This movie was absolutely fantastic! I loved it.\n",
      "Predicted Sentiment: Negative with [45.786903]% accuracy\n",
      "\n",
      "Review: Worst movie ever. I regret watching it.\n",
      "Predicted Sentiment: Positive with [52.3116]% accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(new_padded)\n",
    "\n",
    "# Convert probabilities to labels (0 = negative, 1 = positive)\n",
    "labels = [\"Negative\" if pred < 0.5 else \"Positive\" for pred in predictions]\n",
    "\n",
    "# Print results\n",
    "for review, sentiment, pred in zip(new_reviews, labels, predictions):\n",
    "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment} with {pred*100}% accuracy\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How This Works:\n",
    "* Tokenize the new review → Converts words into numbers.\n",
    "* Convert to sequences → Matches our model input format.\n",
    "* Pad the sequence → Ensures consistent length (100).\n",
    "* Predict sentiment → Outputs a probability between 0 and 1.\n",
    "* Convert to \"Positive\" or \"Negative\" → If probability > 0.5, it's positive, else negative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
